{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 27s 2us/step\n",
      "encoded word sequence: [2, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 2, 744, 35, 3715, 761, 61, 5766, 452, 2, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 2, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 2, 4, 1615, 5, 2, 7, 5168, 17, 13, 2, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 2, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 2, 145, 143, 5122, 12, 2, 537, 746, 537, 537, 15, 2, 4, 2, 594, 7, 5168, 94, 2, 3987, 2, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 2, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 2, 2, 19, 49, 7, 4, 1885, 2, 1118, 25, 80, 126, 842, 10, 10, 2, 2, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 2, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 2, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 2, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 2, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 2, 1775, 3353, 2, 1846, 4, 2, 7, 154, 5, 4, 518, 53, 2, 2, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 1202, 2, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 2, 13, 188, 1076, 3222, 19, 4, 2, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 2, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 2, 804, 2, 7, 4, 2, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 2, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 2, 15, 566, 30, 579, 21, 64, 2574] class: 1\n",
      "x_train.shape: (25000, 100) x_test.shape: (25000, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solomon/lab/deep-learning-python/env/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 124s 5ms/step - loss: 0.6747 - acc: 0.5609 - val_loss: 0.6299 - val_acc: 0.6211\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 125s 5ms/step - loss: 0.5645 - acc: 0.6976 - val_loss: 0.4465 - val_acc: 0.7940\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 131s 5ms/step - loss: 0.4169 - acc: 0.8070 - val_loss: 0.3852 - val_acc: 0.8231\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 141s 6ms/step - loss: 0.3595 - acc: 0.8407 - val_loss: 0.3787 - val_acc: 0.8254\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 148s 6ms/step - loss: 0.3209 - acc: 0.8609 - val_loss: 0.3737 - val_acc: 0.8328\n",
      "25000/25000 [==============================] - 23s 902us/step\n",
      "test score: 0.37373370667219163  test accuracy: 0.8327599997711181\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   This program will classify reviews from IMDB based on sentiment, positive or\n",
    "#   negative.  We will used the IMDB database that comes with Keras. \n",
    "#   This data has already preprocessed the reviews.  This preprocessing \n",
    "#   replaces the actual works with the encoding.  So the second most \n",
    "#   popular word is replaced by 2, third most popular by 3, etc.    \n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "#   Supress warning and informational messages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "#   Set parameters for data to use\n",
    "NUM_WORDS = 6000        # the top most n frequent words to consider\n",
    "SKIP_TOP = 2            # Skip the top most words that are likely (the, and, a)\n",
    "MAX_REVIEW_LEN = 100    # Max number of words from a review.\n",
    "\n",
    "#   Load pre-processed sentiment classified review data from IMDB Database\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = NUM_WORDS,\n",
    "                                        skip_top=SKIP_TOP)\n",
    "#   Print a sample\n",
    "#  returns word index vector (ex. [2, 4, 2, 2, 33, 2804, ...]) and class (0 or 1) \n",
    "print(\"encoded word sequence:\", x_train[3], \"class:\", y_train[3])  \n",
    "\n",
    "\n",
    "#   Pad and truncate the review word sequences so they are all the same length\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = MAX_REVIEW_LEN)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = MAX_REVIEW_LEN)\n",
    "print('x_train.shape:', x_train.shape, 'x_test.shape:', x_test.shape)\n",
    "\n",
    "#   The Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(NUM_WORDS, 64 ))\n",
    "model.add(LSTM(64, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#   Compile\n",
    "model.compile(loss='binary_crossentropy',  \n",
    "            optimizer='adam',              \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "#   Train\n",
    "BATCH_SIZE = 24\n",
    "EPOCHS = 5\n",
    "cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n",
    "model.fit(x_train, y_train, BATCH_SIZE, epochs=EPOCHS, \n",
    "            validation_data=(x_test, y_test), \n",
    "            callbacks=[cbk_early_stopping] )\n",
    "\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=BATCH_SIZE)\n",
    "print('test score:', score, ' test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          384000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 417,089\n",
      "Trainable params: 417,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
